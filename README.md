# Projeto-Airflow
√â uma excelente adi√ß√£o\! Incluirei uma se√ß√£o detalhada sobre como o usu√°rio pode fazer o *setup* e rodar o projeto localmente usando Docker e Astro CLI.

## Pok√©mon Data Ingestion and Database Migration Pipeline

Este projeto demonstra um pipeline de engenharia de dados completo, que coleta dados de uma API externa, valida-os, armazena-os em um banco de dados em nuvem e, em seguida, realiza uma migra√ß√£o de dados em lote para um banco de dados local.

Utilizamos uma combina√ß√£o robusta de tecnologias modernas para construir, orquestrar e implantar esta solu√ß√£o.

### üíª Tecnologias Utilizadas

| Categoria | Tecnologia | Uso |
| :---: | :---: | :--- |
| **Linguagem** | Python | L√≥gica do pipeline, scripts de extra√ß√£o e valida√ß√£o. |
| **Orquestra√ß√£o** | Apache Airflow / Astronomer | Orquestra√ß√£o do fluxo de trabalho (DAGs) e agendamento a cada minuto. |
| **Containeriza√ß√£o** | Docker | Ambiente de desenvolvimento e deploy consistente. |
| **Banco de Dados (OLTP)** | PostgreSQL (Render Cloud) | Armazenamento principal e em tempo real dos dados coletados. |
| **Banco de Dados (OLAP/Local)** | DuckDB | Migra√ß√£o e processamento em lote dos √∫ltimos 5 registros. |
| **Implanta√ß√£o (Cloud)** | AWS (via Astronomer) | Implanta√ß√£o e gerenciamento do ambiente Airflow. |
| **API** | API de Pok√©mon (Externa) | Fonte de dados para extra√ß√£o de informa√ß√µes aleat√≥rias de Pok√©mon. |
| **CLI** | Astro CLI | Ferramenta para desenvolvimento local e deploy do Airflow. |

### üöÄ Funcionalidades do Projeto

1.  **Extra√ß√£o de Dados:** Coleta informa√ß√µes (nome, tipo) de um Pok√©mon aleat√≥rio de uma API externa usando a biblioteca `requests`. O hor√°rio da extra√ß√£o tamb√©m √© registrado.
2.  **Valida√ß√£o de Dados:** Utiliza **Pydantic** para validar o contrato de dados, garantindo que as informa√ß√µes extra√≠das estejam no formato e tipo esperados antes de serem inseridas no banco.
3.  **Carregamento em Tempo Real:** O Airflow agenda a execu√ß√£o do pipeline a **cada minuto**, inserindo o novo registro diretamente no banco de dados **PostgreSQL** hospedado na **Render Cloud**.
4.  **Migra√ß√£o de Dados em Lote (Batch):** A cada execu√ß√£o, uma task separada √© respons√°vel por:
      * Capturar os **5 √∫ltimos registros** do PostgreSQL.
      * Inserir esses dados em *batch* no **DuckDB** (banco de dados anal√≠tico local no contexto do Airflow). Esta etapa demonstra um processo simples de *migra√ß√£o* e *acumula√ß√£o* de dados de um OLTP para um OLAP.
5.  **Explora√ß√£o do Airflow:**
      * O projeto explora **diversas formas de se criar uma DAG** e **ordenar tasks**.
      * Demonstra a **customiza√ß√£o de operadores de banco de dados** ao interagir com o DuckDB, tanto utilizando a interface (UI) do Airflow para adicionar a conex√£o quanto implementando a l√≥gica de conex√£o diretamente via c√≥digo.

### üîß Como Baixar e Testar o Projeto Localmente (Docker & Astro CLI)

A maneira mais eficiente de testar e desenvolver este projeto √© utilizando o **Astro CLI**, que gerencia o ambiente Docker completo do Airflow, garantindo que todas as depend√™ncias (Python, Airflow e o sistema operacional) estejam isoladas e corretas.

#### Pr√©-requisitos

1.  **Docker:** Deve estar instalado e em execu√ß√£o em sua m√°quina.
2.  **Astro CLI:** Instale a ferramenta de linha de comando da Astronomer.

#### 1\. Clonar o Reposit√≥rio

Baixe o c√≥digo do projeto:

```bash
git clone https://github.com/Marcelo2506/Projeto-Airflow.git
cd Projeto-Airflow
```

#### 2\. Configurar Vari√°veis de Conex√£o

Para que o Airflow se conecte ao seu PostgreSQL na Render, voc√™ precisar√° configurar as vari√°veis de ambiente.

Crie um arquivo chamado **`.env`** na pasta raiz do projeto e adicione as suas credenciais do PostgreSQL (Render):

```bash
# Exemplo de configura√ß√£o de conex√£o para o PostgreSQL na Render
POSTGRES_HOST=<SEU_HOST_POSTGRES>
POSTGRES_USER=<SEU_USER_POSTGRES>
POSTGRES_PASSWORD=<SUA_SENHA_POSTGRES>
POSTGRES_DB=<SEU_BANCO_POSTGRES>
POSTGRES_PORT=5432
```

*O Astro CLI utilizar√° este arquivo para injetar as vari√°veis de ambiente dentro dos containers do Airflow.*

#### 3\. Iniciar o Ambiente Airflow (Docker)

Com o Astro CLI, voc√™ pode inicializar o Airflow e todos os servi√ßos de suporte (Scheduler, Webserver, Worker, etc.) com um √∫nico comando:

```bash
astro dev start
```

Este comando far√° o seguinte:

1.  Construir√° a imagem Docker do projeto, instalando todas as depend√™ncias listadas.
2.  Levantar√° os containers do Airflow e do Postres local (usado pelo Airflow para metadados).
3.  As DAGs ser√£o carregadas automaticamente.

Para garantir a seguran√ßa e a funcionalidade correta do pipeline:
Certifique-se de que a linha AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES=include.schema.PokemonSchema esteja presente no seu arquivo .env e que build-essential esteja em packages.txt.

#### 4\. Acessar a UI do Airflow

Ap√≥s o comando `astro dev start` finalizar (pode levar alguns minutos na primeira vez), acesse a interface do Airflow:

**URL:** `http://localhost:8080/`
**Login Padr√£o:** `admin`
**Senha Padr√£o:** `admin`

Voc√™ poder√° ver as DAGs listadas e observar as execu√ß√µes sendo agendadas e rodando a cada minuto.

#### 5\. Parar o Ambiente

Quando terminar de testar, utilize o seguinte comando para derrubar os containers e limpar os recursos:

```bash
astro dev stop
```

### üì¶ Estrutura e Extensibilidade

O c√≥digo do projeto foi implementado com foco em **organiza√ß√£o de p√°ginas** e **l√≥gica de programa√ß√£o limpa**, permitindo que ele seja facilmente compreendido e **incrementado** como qualquer outro projeto de desenvolvimento de software robusto.

### üõ†Ô∏è Implanta√ß√£o em Nuvem

O projeto √© completo e otimizado para a plataforma Astronomer (deploy em nuvem, como na AWS). O deploy pode ser feito de forma simples utilizando o **Astro CLI** ap√≥s configurar o *Workspace*:

```bash
astro deploy
```

### üìù Depend√™ncias Adicionais

Este projeto utiliza as seguintes bibliotecas Python, que devem ser instaladas (e est√£o configuradas no `Dockerfile` e `requirements.txt` para o Astro CLI):

```
requests >=2.32.5,<3.0.0
python-dotenv >=1.1.1,<2.0.0
pydantic >=2.12.0,<3.0.0

duckdb >=1.4.1,<2.0.0
airflow-provider-duckdb >=0.2.0,<0.3.0
astro-sdk-python[duckdb] >=1.8.1,<2.0.0
apache-airflow-providers-postgres
```

### üñºÔ∏è Resultados e Evid√™ncias

As seguintes imagens demonstram o projeto em execu√ß√£o e seus resultados:

#### 1. Consulta ao PostgreSQL (PgAdmin)
Mostra que os dados (id, nome, tipo, `created_at`) est√£o sendo corretamente inseridos e acumulados no banco de dados PostgreSQL.

![Imagem do PgAdmin mostrando a tabela 'pokemons' populada.](pics/PgAdmin%20Rodando.png)

#### 2. Consulta ao DuckDB (DuckerDB UI)
Mostra o resultado da migra√ß√£o em lote dos dados do PostgreSQL para o DuckDB, que armazena os registros acumulados em um fluxo de migra√ß√£o.

![Imagem da interface do DuckerDB mostrando a tabela 'my_db.pokemons' com 36 linhas, incluindo 'lotad' e 'illumise'.](pics/duckerdb.png)

#### 3. Orquestra√ß√£o no Airflow (Webserver)
Vis√£o da interface padr√£o do Airflow, confirmando o agendamento e o status de sucesso das DAGs.

![Imagem da interface do Airflow (padr√£o) listando as DAGs e seu √∫ltimo/pr√≥ximo agendamento.](pics/airflow.png)

#### 4. Implanta√ß√£o e Monitoramento (Astro CLI/Astronomer)
Vis√£o da plataforma Astronomer/Astro CLI, demonstrando o ambiente de deploy gerenciado na nuvem.

![Imagem da interface da Astronomer mostrando as DAGs, o status de execu√ß√£o ('Successful', 'Failed', 'In Progress') e o agendamento.](pics/astro%20cli.jpg)